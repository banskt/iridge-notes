{
  
    
        "post0": {
            "title": "Basic comparison of ridge regression methods",
            "content": "About . Just wanted to have a sanity check that all ridge regression methods perform similarly. . import numpy as np import scipy from scipy import linalg as sc_linalg from scipy import sparse as sc_sparse from sklearn.linear_model import Ridge import glmnet_python from glmnet import glmnet from glmnetPrint import glmnetPrint from glmnetCoef import glmnetCoef from glmnetPredict import glmnetPredict import matplotlib.pyplot as plt import sys sys.path.append(&quot;../../utils/&quot;) import mpl_stylesheet mpl_stylesheet.banskt_presentation(fontfamily = &#39;latex-clearsans&#39;, fontsize = 18, colors = &#39;banskt&#39;, dpi = 72) . ../../utils/mpl_stylesheet.py:26: MatplotlibDeprecationWarning: Support for setting the &#39;text.latex.preamble&#39; or &#39;pgf.preamble&#39; rcParam to a list of strings is deprecated since 3.3 and will be removed two minor releases later; set it to a single string instead. matplotlib.rcParams[&#39;text.latex.preamble&#39;] = [r&#39; usepackage[scaled=.86]{ClearSans}&#39;, . def standardize(X): Xnorm = (X - np.mean(X, axis = 0)) #Xstd = Xnorm / np.std(Xnorm, axis = 0) Xstd = Xnorm / np.sqrt((Xnorm * Xnorm).sum(axis = 0)) return Xstd def ridge_data(nsample, nvar, errsigma): X = np.random.normal(0, 1, nsample * nvar).reshape(nsample, nvar) X = standardize(X) btrue = np.random.normal(0, 1, nvar) y = np.dot(X, btrue) + np.random.normal(0, errsigma, nsample) y = y - np.mean(y) return X, y, btrue . def rsquare(ytrue, ypred): sst = np.sum(np.square(ytrue - np.mean(ytrue))) sse = np.sum(np.square(ytrue - ypred)) rsq = 1 - (sse / sst) return rsq . def logpdf_multivariate_gauss(x, mu, cov): &#39;&#39;&#39; Caculate the multivariate normal density (pdf) Keyword arguments: x = numpy array of a &quot;d x 1&quot; sample vector mu = numpy array of a &quot;d x 1&quot; mean vector cov = &quot;numpy array of a d x d&quot; covariance matrix &#39;&#39;&#39; assert(mu.shape[0] &gt; mu.shape[1]), &#39;mu must be a row vector&#39; assert(x.shape[0] &gt; x.shape[1]), &#39;x must be a row vector&#39; assert(cov.shape[0] == cov.shape[1]), &#39;covariance matrix must be square&#39; assert(mu.shape[0] == cov.shape[0]), &#39;cov_mat and mu_vec must have the same dimensions&#39; assert(mu.shape[0] == x.shape[0]), &#39;mu and x must have the same dimensions&#39; part1 = - nsample * 0.5 * np.log(2. * np.pi) - 0.5 * np.linalg.slogdet(cov)[1] xlm = x - mu part2 = - 0.5 * np.dot(xlm.T, np.dot(np.linalg.inv(cov), xlm)) return float(part1 + part2) def ridge_em(X, Y, s2, sb2, niter = 10): XTX = np.dot(X.T, X) XTY = np.dot(X.T, Y) YTY = np.dot(Y.T, Y) nsample = X.shape[0] nvar = X.shape[1] loglik = np.zeros(niter) i = 0 while i &lt; niter: V = XTX + np.eye(nvar) * (s2 / sb2) Vinv = sc_linalg.cho_solve(sc_linalg.cho_factor(V, lower=True), np.eye(nvar)) SigmaY = sb2 * np.dot(X, X.T) + np.eye(nsample) * s2 loglik[i] = logpdf_multivariate_gauss(Y.reshape(-1, 1), np.zeros((nsample, 1)), SigmaY) Sigmab = s2 * Vinv # posterior variance of b mub = np.dot(Vinv, XTY) # posterior mean of b b2m = np.einsum(&#39;i,j-&gt;ij&#39;, mub, mub) + Sigmab s2 = (YTY + np.dot(XTX, b2m).trace() - 2 * np.dot(XTY, mub)) / nsample sb2 = np.sum(np.square(mub) + np.diag(Sigmab)) / nvar i += 1 return s2, sb2, loglik, mub.reshape(-1), Sigmab . def ridge_ols(X, Y, lmbda): XTX = np.dot(X.T, X) XTY = np.dot(X.T, Y) nvar = X.shape[1] V = XTX + np.eye(nvar) * lmbda Vinv = sc_linalg.cho_solve(sc_linalg.cho_factor(V, lower=True), np.eye(nvar)) bhat = np.dot(Vinv, XTY) return bhat . def svd2XTX(svd): U = svd[0] S = svd[1] Vh = svd[2] nmax = max(S.shape[0], Vh.shape[0]) Sdiag = np.zeros((nmax, nmax)) Sdiag[np.diag_indices(S.shape[0])] = np.square(S) return np.dot(Vh.T, np.dot(Sdiag, Vh)) def c_func(nsample, s2, ElogW): val = - 0.5 * nsample * np.log(2. * np.pi * s2) val += - 0.5 * np.sum(ElogW) return val def h1_func(X, Y, s2, mu, Wbar): val = - (0.5 / s2) * (np.sum(np.square(Y - np.dot(X, mu))) + np.sum(np.square(mu) / Wbar)) return val def h2_func(svd, Sigma, Wbar): XTX = svd2XTX(svd) (sign, logdet) = np.linalg.slogdet(Sigma) val = - 0.5 * np.trace(np.dot(XTX + np.diag(1 / Wbar), Sigma)) + 0.5 * logdet return val def ebmr_initialize(X, Y): svd = sc_linalg.svd(X) XTY = np.dot(X.T, Y) mu = np.zeros(nvar) Sigma = np.zeros((nvar, nvar)) return svd, XTY, mu, Sigma def update_Sigma(svd, Wbar, nvar): XTX = svd2XTX(svd) Sigma = sc_linalg.cho_solve(sc_linalg.cho_factor(XTX + np.diag(1 / Wbar), lower=True), np.eye(nvar)) return Sigma def update_mu(Sigma, XTY): return np.dot(Sigma, XTY) def update_s2(X, Y, mu, Wbar, nsample): A = np.sum(np.square(Y - np.dot(X, mu))) s2 = (A + np.sum(np.square(mu) / Wbar)) / nsample return s2 def update_wg_ridge(mu, Sigma, s2, nvar): bj2 = np.square(mu) + np.diag(Sigma) * s2 W = np.repeat(np.sum(bj2) / s2 / nvar, nvar) KLW = 0. return W, KLW def update_elbo(X, Y, s2, mu, Sigma, Wbar, KLw, svd, nsample, nvar): ElogW = np.log(Wbar) elbo = c_func(nsample, s2, ElogW) + h1_func(X, Y, s2, mu, Wbar) + h2_func(svd, Sigma, Wbar) + KLw return elbo def ebmr(X, Y, niter = 10, tol = 1e-4): nvar = X.shape[1] nsample = X.shape[0] svdX, XTY, mu, Sigma = ebmr_initialize(X, Y) s2 = np.var(Y) Wbar = np.ones(nvar) elbo = -np.inf i = 0 while i &lt; niter: #print(i) #Sigma = update_Sigma(svdX, Wbar, nvar) XTX = svd2XTX(svdX) Sigma = sc_linalg.cho_solve(sc_linalg.cho_factor(XTX + np.diag(1 / Wbar), lower=True), np.eye(nvar)) mu = update_mu(Sigma, XTY) s2 = update_s2(X, Y, mu, Wbar, nsample) Wbar, KLw = update_wg_ridge(mu, Sigma, s2, nvar) elbo_new = update_elbo(X, Y, s2, mu, Sigma, Wbar, KLw, svdX, nsample, nvar) if elbo_new - elbo &lt; tol: break elbo = elbo_new i += 1 return s2, mu, Sigma, Wbar . nsample = 50 nvar = 100 nsim = 20 errsigmas = np.logspace(-0.1, 1, 5) r2 = [None for i in errsigmas] for i, sd in enumerate(errsigmas): lmbda = np.square(sd) r2[i] = dict() r2[i][&#39;ridge_mle&#39;] = list() r2[i][&#39;ridge_em&#39;] = list() r2[i][&#39;ebmr&#39;] = list() r2[i][&#39;sklearn&#39;] = list() r2[i][&#39;sp_lsqr&#39;] = list() r2[i][&#39;glmnet&#39;] = list() for isim in range(nsim): X, y, btrue = ridge_data(nsample, nvar, sd) # Ridge_OLS b_ridge_ols = ridge_ols(X, y, lmbda) y_ridge_ols = np.dot(X, b_ridge_ols) r2[i][&#39;ridge_mle&#39;].append(rsquare(y, y_ridge_ols)) #r2[i][&#39;ridge_ols&#39;].append(y_ridge_ols) #r2[i][&#39;ridge_ols&#39;].append(np.square(y - y_ridge_ols)) #r2[i][&#39;ridge_ols&#39;].append(y) # Ridge EM _, _, _, b_ridge_em, _ = ridge_em(X, y, 1, 1, 500) r2[i][&#39;ridge_em&#39;].append(rsquare(y, np.dot(X, b_ridge_em))) # EBMR _, b_ebmr, _, _ = ebmr(X, y, 1000) y_ebmr = np.dot(X, b_ebmr) r2[i][&#39;ebmr&#39;].append(rsquare(y, y_ebmr)) #Sklearn Ridge clf = Ridge(alpha=lmbda, fit_intercept = False, normalize = False, solver = &#39;sparse_cg&#39;) clf.fit(X, y) b_sklearn = clf.coef_ y_sklearn = np.dot(X, b_sklearn) r2[i][&#39;sklearn&#39;].append(rsquare(y, y_sklearn)) #Sparse Lsqr b_sp_lsqr = sc_sparse.linalg.lsqr(X, y, damp=np.sqrt(lmbda))[0] #b_sp_lsqr = my_lsqr(X, y, damp=1.0)[0] y_sp_lsqr = np.dot(X, b_sp_lsqr) r2[i][&#39;sp_lsqr&#39;].append(rsquare(y, y_sp_lsqr)) #r2[i][&#39;sp_lsqr&#39;].append(y_sp_lsqr) #r2[i][&#39;sp_lsqr&#39;].append(np.square(y - y_sp_lsqr)) #r2[i][&#39;sp_lsqr&#39;].append(y) #glmnet lmbda_glmnet = lmbda / X.shape[0] fit = glmnet(x = X.copy(), y = y.copy(), family = &#39;gaussian&#39;, alpha = 0.0, intr = False, lambdau = np.array([lmbda_glmnet, 1.0])) b_glmnet = glmnetCoef(fit, s = np.float64([lmbda_glmnet]), exact = False)[1:].reshape(-1) y_glmnet = np.dot(X, b_glmnet) r2[i][&#39;glmnet&#39;].append(rsquare(y, y_glmnet)) #r2[i][&#39;glmnet&#39;].append(y_glmnet) #r2[i][&#39;glmnet&#39;].append(np.square(y - y_glmnet)) #r2[i][&#39;glmnet&#39;].append(y) . fig = plt.figure(figsize = (16,6)) ax1 = fig.add_subplot(111) colors = {&#39;ridge_em&#39;: &#39;#2D69C4&#39;, &#39;ebmr&#39;: &#39;#CC2529&#39;, &#39;sklearn&#39;: &#39;#93AA00&#39;, &#39;sp_lsqr&#39;: &#39;#535154&#39;, &#39;glmnet&#39;: &#39;#6B4C9A&#39;, &#39;ridge_mle&#39;: &#39;#FFB300&#39;} facecolors = {&#39;ridge_em&#39;: &#39;#719ad8&#39;, &#39;ebmr&#39;: &#39;#f2888b&#39;, &#39;sklearn&#39;: &#39;#c4d64f&#39;, &#39;sp_lsqr&#39;: &#39;#a6a3a7&#39;, &#39;glmnet&#39;: &#39;#a98fd2&#39;, &#39;ridge_mle&#39;: &#39;#fbd67e&#39;} barwidth = 0.1 nsigma = len(errsigmas) xpos = [(k+1)*2 for k in range(nsigma)] plot_methods = [&#39;ridge_mle&#39;, &#39;sklearn&#39;, &#39;sp_lsqr&#39;, &#39;ridge_em&#39;, &#39;ebmr&#39;, &#39;glmnet&#39;] bxplt = [None for x in plot_methods] for i, method in enumerate(plot_methods): #for i, method in enumerate([&#39;ridge_ols&#39;, &#39;sp_lsqr&#39;, &#39;glmnet&#39;]): #pdata = [np.hstack(r2[k][method]) for k in range(nsigma)] pdata = [r2[k][method] for k in range(nsigma)] xloc = [x + (i * barwidth) + (i * barwidth / 3) for x in xpos] medianprops = dict(linewidth=2, color = colors[method]) whiskerprops = dict(linewidth=2, color = facecolors[method]) boxprops = dict(linewidth=2, color = colors[method], facecolor = facecolors[method]) bxplt[i] = ax1.boxplot(pdata, positions = xloc, showfliers = False, showcaps = False, widths=barwidth, patch_artist=True, notch = False, boxprops = boxprops, medianprops = medianprops, whiskerprops = whiskerprops, ) leghandles = [x[&quot;boxes&quot;][0] for x in bxplt] ax1.legend(leghandles, plot_methods, loc=&#39;lower left&#39;, handlelength = 1.2, labelspacing = 0.2,) ax1.set_xticks(xpos) ax1.set_xticklabels([f&#39;{x:.2f}&#39; for x in errsigmas]) ax1.set_xlim(min(xpos) - 1, max(xpos) + 1) ax1.set_xlabel(r&#39;Prior $ sigma$&#39;) ax1.set_ylabel(r&#39;$R^2$&#39;) ax1.set_title(r&#39;n = 50, p = 100, fixed $ lambda$ estimated from prior&#39;) #plt.savefig(&#39;compare_ridge_methods.png&#39;, bbox_inches=&#39;tight&#39;, facecolor=&#39;white&#39;, transparent=True) plt.tight_layout() plt.show() . def jitter(arr): stdev = .1 * (max(arr) - min(arr)) return arr + abs(np.random.randn(len(arr)) * stdev) fig = plt.figure(figsize = (8, 8)) ax1 = fig.add_subplot(111) nshow = 2 for i, method in enumerate(plot_methods): ydata = r2[nshow][method] if method == &#39;sklearn&#39; or method == &#39;sp_lsqr&#39;: ydata = jitter(ydata) ax1.scatter(r2[nshow][&#39;ridge_mle&#39;], ydata, color = colors[method]) ax1.set_title(f&#39;Comparison of $R^2$ ($ sigma$ = {errsigmas[nshow]:.2f})&#39;, pad = 20) ax1.set_xlabel(&#39;ridge_mle&#39;) ax1.set_ylabel(&#39;All ridge regression methods&#39;) #ax1.set_xticks([0.03, 0.04, 0.05]) ax1.set_xlim([0.2, 0.5]) ax1.set_ylim([0, 1.05]) ax1.plot([0,1],[0,1], ls = &#39;dashed&#39;, color = &#39;gray&#39;) #plt.savefig(&#39;compare_ridge_methods_scatter.png&#39;, bbox_inches=&#39;tight&#39;, facecolor=&#39;white&#39;, transparent=True) plt.show() .",
            "url": "https://banskt.github.io/iridge-notes/jupyter/2020/11/02/basic-comparison-ridge-regression-methods.html",
            "relUrl": "/jupyter/2020/11/02/basic-comparison-ridge-regression-methods.html",
            "date": " • Nov 2, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://banskt.github.io/iridge-notes/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://banskt.github.io/iridge-notes/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://banskt.github.io/iridge-notes/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}